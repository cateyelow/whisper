{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c684276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (manager-core).\n",
      "Your token has been saved to D:\\.cache\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd72e655",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfcac7ede7f4d14aec4b5676e369bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/12160783 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset audiofolder/default to D:/.cache/datasets/audiofolder/default-f6cde19592396743/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11d910395f324004a12a456768d68f0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2439752 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9250deb2fc2e4878b46ac979b60f6b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing checksums:  10%|#         | 249434/2439752 [00:05<00:43, 49882.71it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49094ae3a8294f28994c6cd4c2307821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/9721031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3454a8964b9439c9ed6f0bf4e5cc66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing checksums:   2%|2         | 240734/9721031 [00:05<03:16, 48142.37it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f4f7672570416688aa1640865f4d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/9721031 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load Datasets\n",
    "from datasets import load_dataset\n",
    "dataset_custom = load_dataset('audiofolder', data_dir='E:/HuggingFace/KoreanSpeech/')                              \n",
    "dataset_zeroth = load_dataset(\"Bingsu/zeroth-korean\")\n",
    "dataset_fleurs = load_dataset('google/fleurs', 'ko_kr')\n",
    "dataset_common_voice = load_dataset('mozilla-foundation/common_voice_12_0', 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6558d77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio'],\n",
      "        num_rows: 2439751\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 457\n",
      "    })\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 22263\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 2307\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 226\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'num_samples', 'path', 'audio', 'transcription', 'raw_transcription', 'gender', 'lang_id', 'language', 'lang_group_id'],\n",
      "        num_rows: 382\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 94\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 30\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 29\n",
      "    })\n",
      "    other: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 1009\n",
      "    })\n",
      "    invalidated: Dataset({\n",
      "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
      "        num_rows: 38\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset_custom)\n",
    "print(dataset_zeroth)\n",
    "print(dataset_fleurs)\n",
    "print(dataset_common_voice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c23972b3",
   "metadata": {},
   "source": [
    "PreProcessing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "163800fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fleurs = dataset_fleurs.rename_column('transcription', 'text')\n",
    "dataset_common_voice = dataset_polyai.rename_column(\"sentence\", 'text')\n",
    "\n",
    "use_cols=['audio', 'text']\n",
    "dataset_fleurs = dataset_fleurs.remove_columns([col for col in dataset_fleurs.column_names['train'] if col not in use_cols])\n",
    "dataset_polyai = dataset_polyai.remove_columns([col for col in dataset_polyai.column_names['train'] if col not in use_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ceb971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, IterableDatasetDict\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import interleave_datasets\n",
    "from datasets import Audio\n",
    "\n",
    "dataset_polyai = dataset_polyai.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset_fleurs = dataset_fleurs.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset_custom = dataset_custom.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "stopping_strategy=\"all_exhausted\"\n",
    "data_dict = IterableDatasetDict()\n",
    "\n",
    "data_dict[\"train\"] = interleave_datasets(\n",
    "    [\n",
    "        dataset_fleurs['train'],\n",
    "        dataset_polyai['train'],\n",
    "        dataset_zeroth['train'],\n",
    "        dataset_custom['train'],\n",
    "    ],\n",
    "        stopping_strategy=stopping_strategy\n",
    ")\n",
    "\n",
    "data_dict[\"test\"] = interleave_datasets(\n",
    "    [\n",
    "        dataset_fleurs['test'],\n",
    "        dataset_zeroth['test'],\n",
    "    ],\n",
    "        stopping_strategy=stopping_strategy\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f42ef4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['audio', 'text'], 'test': ['audio', 'text']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict = DatasetDict(data_dict)\n",
    "data_dict.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9399bc3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2e178c7a0945e2b7f8c31282187a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84364f03c2ee4e04a4a002011ec39955",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/842 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7691eda81be84b75a5cad91c8c156b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c3b71bf4ed400a8369a65648dda1e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.20M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac4969e45a345d7a701f4267888fcd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075817ceecf540368eef55032fa2e83e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)main/normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb66de7eed9402db757740dd94409ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)in/added_tokens.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fee95af415a0493a989fddc0ad2a6f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.08k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:                 호주의 전 보수 정부는 인도와 중국 같은 나라는 온실 가스 방출 목표에 제한을 받지 않는 반면 석탄 수출에 크게 의존하고 있는 자국 경제에는 악영향을 미칠 것이라며 교토 의정서 비준을 거부했다\n",
      "Decoded w/ special:    <|startoftranscript|><|ko|><|transcribe|><|notimestamps|>호주의 전 보수 정부는 인도와 중국 같은 나라는 온실 가스 방출 목표에 제한을 받지 않는 반면 석탄 수출에 크게 의존하고 있는 자국 경제에는 악영향을 미칠 것이라며 교토 의정서 비준을 거부했다<|endoftext|>\n",
      "Decoded w/out special: 호주의 전 보수 정부는 인도와 중국 같은 나라는 온실 가스 방출 목표에 제한을 받지 않는 반면 석탄 수출에 크게 의존하고 있는 자국 경제에는 악영향을 미칠 것이라며 교토 의정서 비준을 거부했다\n",
      "Are equal:             True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209ec4ea5ac140b7a8fd323e0f8af938",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/66789 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d533612f97c482d9e76cacad0c6a150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/914 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load FreatureExtravtor\n",
    "from transformers import WhisperFeatureExtractor\n",
    "#Load WhisperTokenizer\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "#Prepare Dataset\n",
    "def prepare_dataset(batch):\n",
    "    from transformers import WhisperFeatureExtractor\n",
    "    from transformers import WhisperTokenizer \n",
    "    feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "    tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "#Verify Tokenizer\n",
    "input_str = data_dict['train'][0]['text']\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n",
    "\n",
    "#Combine To Create A WhisperProcessor\n",
    "from transformers import WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "#ReSampling\n",
    "from datasets import Audio\n",
    "\n",
    "dataset = data_dict.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "dataset = dataset.map(prepare_dataset, \n",
    "                            remove_columns=dataset.column_names[\"train\"], num_proc=24,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f04de1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fce7eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb587d5c0f794ebe802accd3f52dbdef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61bebdeec2ab43659832d02233e9faf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b175f6b2be741df97b97eac3a7582f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8062ff8d8534e16a1ef6ecc0fecb977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/3.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning https://huggingface.co/trueorfalse441/whisper-small-ko into local empty directory.\n",
      "c:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "566bf5d87197412dbf12c09def4d8582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache = True` is incompatible with gradient checkpointing. Setting `use_cache = False`...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2082, 'learning_rate': 2.1000000000000002e-06, 'epoch': 0.01}\n",
      "{'loss': 1.3446, 'learning_rate': 4.600000000000001e-06, 'epoch': 0.01}\n",
      "{'loss': 0.6593, 'learning_rate': 7.100000000000001e-06, 'epoch': 0.02}\n",
      "{'loss': 0.5063, 'learning_rate': 9.600000000000001e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9380aa22622f47318d99d18108d62bea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43873330950737, 'eval_wer': 128.658125421443, 'eval_runtime': 254.4377, 'eval_samples_per_second': 3.592, 'eval_steps_per_second': 0.452, 'epoch': 0.02}\n",
      "{'loss': 0.3946, 'learning_rate': 9.927586206896552e-06, 'epoch': 0.03}\n",
      "{'loss': 0.2982, 'learning_rate': 9.841379310344828e-06, 'epoch': 0.04}\n",
      "{'loss': 0.2942, 'learning_rate': 9.755172413793104e-06, 'epoch': 0.04}\n",
      "{'loss': 0.26, 'learning_rate': 9.66896551724138e-06, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e740e07a285b44129a96929e7b768d3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.30883336067199707, 'eval_wer': 24.582303139282235, 'eval_runtime': 146.4515, 'eval_samples_per_second': 6.241, 'eval_steps_per_second': 0.785, 'epoch': 0.05}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (2) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.2428, 'learning_rate': 9.582758620689656e-06, 'epoch': 0.05}\n",
      "{'loss': 0.2117, 'learning_rate': 9.496551724137932e-06, 'epoch': 0.06}\n",
      "{'loss': 0.2446, 'learning_rate': 9.410344827586208e-06, 'epoch': 0.07}\n",
      "{'loss': 0.2092, 'learning_rate': 9.324137931034484e-06, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c27432d6774d379fdc29ff1bd4e724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.28776752948760986, 'eval_wer': 22.5668689593167, 'eval_runtime': 149.2947, 'eval_samples_per_second': 6.122, 'eval_steps_per_second': 0.77, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (3) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1867, 'learning_rate': 9.237931034482759e-06, 'epoch': 0.08}\n",
      "{'loss': 0.1974, 'learning_rate': 9.151724137931035e-06, 'epoch': 0.08}\n",
      "{'loss': 0.21, 'learning_rate': 9.06551724137931e-06, 'epoch': 0.09}\n",
      "{'loss': 0.1628, 'learning_rate': 8.979310344827587e-06, 'epoch': 0.1}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93d2db9358f649fb857d116343f67433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2817244529724121, 'eval_wer': 21.945006368472317, 'eval_runtime': 147.8817, 'eval_samples_per_second': 6.181, 'eval_steps_per_second': 0.778, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (4) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1871, 'learning_rate': 8.893103448275863e-06, 'epoch': 0.1}\n",
      "{'loss': 0.1976, 'learning_rate': 8.806896551724139e-06, 'epoch': 0.11}\n",
      "{'loss': 0.1571, 'learning_rate': 8.720689655172415e-06, 'epoch': 0.11}\n",
      "{'loss': 0.1532, 'learning_rate': 8.634482758620691e-06, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ced507d48345249e26b72f950a9d6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.27165597677230835, 'eval_wer': 22.057391174046604, 'eval_runtime': 148.9396, 'eval_samples_per_second': 6.137, 'eval_steps_per_second': 0.772, 'epoch': 0.12}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (5) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1431, 'learning_rate': 8.548275862068967e-06, 'epoch': 0.13}\n",
      "{'loss': 0.1589, 'learning_rate': 8.462068965517241e-06, 'epoch': 0.13}\n",
      "{'loss': 0.1484, 'learning_rate': 8.375862068965517e-06, 'epoch': 0.14}\n",
      "{'loss': 0.1286, 'learning_rate': 8.289655172413793e-06, 'epoch': 0.14}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2908bde525c047fab88132e56f1c8756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2638859748840332, 'eval_wer': 21.472990185060315, 'eval_runtime': 149.6124, 'eval_samples_per_second': 6.109, 'eval_steps_per_second': 0.769, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (6) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1481, 'learning_rate': 8.20344827586207e-06, 'epoch': 0.15}\n",
      "{'loss': 0.129, 'learning_rate': 8.117241379310346e-06, 'epoch': 0.16}\n",
      "{'loss': 0.131, 'learning_rate': 8.031034482758622e-06, 'epoch': 0.16}\n",
      "{'loss': 0.1267, 'learning_rate': 7.944827586206898e-06, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09869258720b450ea1d4dcfc469fa041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2606123685836792, 'eval_wer': 20.65632726455383, 'eval_runtime': 147.7164, 'eval_samples_per_second': 6.188, 'eval_steps_per_second': 0.779, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (7) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.101, 'learning_rate': 7.858620689655174e-06, 'epoch': 0.17}\n",
      "{'loss': 0.1129, 'learning_rate': 7.77241379310345e-06, 'epoch': 0.18}\n",
      "{'loss': 0.1099, 'learning_rate': 7.686206896551724e-06, 'epoch': 0.19}\n",
      "{'loss': 0.1272, 'learning_rate': 7.600000000000001e-06, 'epoch': 0.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74d7c695e3040e6a9a7cb39d4f1f01b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25675415992736816, 'eval_wer': 21.09837416647936, 'eval_runtime': 153.5299, 'eval_samples_per_second': 5.953, 'eval_steps_per_second': 0.749, 'epoch': 0.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (8) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.1051, 'learning_rate': 7.513793103448277e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1097, 'learning_rate': 7.427586206896552e-06, 'epoch': 0.2}\n",
      "{'loss': 0.1292, 'learning_rate': 7.341379310344828e-06, 'epoch': 0.21}\n",
      "{'loss': 0.0923, 'learning_rate': 7.255172413793104e-06, 'epoch': 0.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52522ce72ac44c258bfe3098f3b41832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.25214657187461853, 'eval_wer': 20.69378886641193, 'eval_runtime': 150.9592, 'eval_samples_per_second': 6.055, 'eval_steps_per_second': 0.762, 'epoch': 0.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (9) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0875, 'learning_rate': 7.1689655172413795e-06, 'epoch': 0.22}\n",
      "{'loss': 0.1081, 'learning_rate': 7.0827586206896555e-06, 'epoch': 0.23}\n",
      "{'loss': 0.1146, 'learning_rate': 6.996551724137932e-06, 'epoch': 0.23}\n",
      "{'loss': 0.1002, 'learning_rate': 6.910344827586208e-06, 'epoch': 0.24}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2427d1e26014e4881c72be783ec5faf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2510691285133362, 'eval_wer': 20.708773507155165, 'eval_runtime': 151.1878, 'eval_samples_per_second': 6.045, 'eval_steps_per_second': 0.761, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (10) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0975, 'learning_rate': 6.824137931034484e-06, 'epoch': 0.25}\n",
      "{'loss': 0.1164, 'learning_rate': 6.737931034482759e-06, 'epoch': 0.25}\n",
      "{'loss': 0.0825, 'learning_rate': 6.651724137931035e-06, 'epoch': 0.26}\n",
      "{'loss': 0.1006, 'learning_rate': 6.565517241379311e-06, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876d83e90aad441cbc9f328bf542923e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24873171746730804, 'eval_wer': 20.52146549786469, 'eval_runtime': 152.4899, 'eval_samples_per_second': 5.994, 'eval_steps_per_second': 0.754, 'epoch': 0.26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (11) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0759, 'learning_rate': 6.479310344827586e-06, 'epoch': 0.27}\n",
      "{'loss': 0.0929, 'learning_rate': 6.393103448275862e-06, 'epoch': 0.28}\n",
      "{'loss': 0.0953, 'learning_rate': 6.306896551724139e-06, 'epoch': 0.28}\n",
      "{'loss': 0.0809, 'learning_rate': 6.220689655172414e-06, 'epoch': 0.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdb54e644634a72aa4dad553c699040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24499008059501648, 'eval_wer': 21.18078969056717, 'eval_runtime': 155.1662, 'eval_samples_per_second': 5.89, 'eval_steps_per_second': 0.741, 'epoch': 0.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (12) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0873, 'learning_rate': 6.13448275862069e-06, 'epoch': 0.29}\n",
      "{'loss': 0.0732, 'learning_rate': 6.048275862068966e-06, 'epoch': 0.3}\n",
      "{'loss': 0.0785, 'learning_rate': 5.9620689655172415e-06, 'epoch': 0.31}\n",
      "{'loss': 0.0891, 'learning_rate': 5.875862068965518e-06, 'epoch': 0.31}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c89662db544e8db540f52fabbcee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24421508610248566, 'eval_wer': 20.42406533303364, 'eval_runtime': 150.5382, 'eval_samples_per_second': 6.072, 'eval_steps_per_second': 0.764, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (13) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0692, 'learning_rate': 5.789655172413794e-06, 'epoch': 0.32}\n",
      "{'loss': 0.0723, 'learning_rate': 5.703448275862069e-06, 'epoch': 0.32}\n",
      "{'loss': 0.089, 'learning_rate': 5.617241379310345e-06, 'epoch': 0.33}\n",
      "{'loss': 0.0666, 'learning_rate': 5.531034482758622e-06, 'epoch': 0.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ba0e30d97a74a6f9959ebb87343df74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24255047738552094, 'eval_wer': 21.705252116580507, 'eval_runtime': 152.9064, 'eval_samples_per_second': 5.978, 'eval_steps_per_second': 0.752, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (14) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0731, 'learning_rate': 5.444827586206897e-06, 'epoch': 0.34}\n",
      "{'loss': 0.0687, 'learning_rate': 5.358620689655173e-06, 'epoch': 0.35}\n",
      "{'loss': 0.0654, 'learning_rate': 5.272413793103449e-06, 'epoch': 0.35}\n",
      "{'loss': 0.0832, 'learning_rate': 5.186206896551724e-06, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53cde46444c4f598b7e69f923322723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2432692050933838, 'eval_wer': 20.214280362628305, 'eval_runtime': 148.9309, 'eval_samples_per_second': 6.137, 'eval_steps_per_second': 0.772, 'epoch': 0.36}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (15) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.083, 'learning_rate': 5.1e-06, 'epoch': 0.37}\n",
      "{'loss': 0.0751, 'learning_rate': 5.013793103448276e-06, 'epoch': 0.37}\n",
      "{'loss': 0.0729, 'learning_rate': 4.9275862068965515e-06, 'epoch': 0.38}\n",
      "{'loss': 0.0749, 'learning_rate': 4.8413793103448284e-06, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0747cbbecf470890586acc175daf02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.24163901805877686, 'eval_wer': 19.44257136435154, 'eval_runtime': 149.2187, 'eval_samples_per_second': 6.125, 'eval_steps_per_second': 0.771, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (16) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0519, 'learning_rate': 4.755172413793104e-06, 'epoch': 0.39}\n",
      "{'loss': 0.0627, 'learning_rate': 4.66896551724138e-06, 'epoch': 0.4}\n",
      "{'loss': 0.073, 'learning_rate': 4.582758620689656e-06, 'epoch': 0.4}\n",
      "{'loss': 0.0869, 'learning_rate': 4.496551724137932e-06, 'epoch': 0.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c152fac28f4d4829bc7bf62d5439f8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23632939159870148, 'eval_wer': 22.102345096276316, 'eval_runtime': 159.0932, 'eval_samples_per_second': 5.745, 'eval_steps_per_second': 0.723, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (17) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0547, 'learning_rate': 4.410344827586207e-06, 'epoch': 0.41}\n",
      "{'loss': 0.0584, 'learning_rate': 4.324137931034483e-06, 'epoch': 0.42}\n",
      "{'loss': 0.0626, 'learning_rate': 4.237931034482759e-06, 'epoch': 0.43}\n",
      "{'loss': 0.062, 'learning_rate': 4.151724137931035e-06, 'epoch': 0.43}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85771f4f07f34681800746f62cd9b738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2380625158548355, 'eval_wer': 20.274218925601257, 'eval_runtime': 153.8578, 'eval_samples_per_second': 5.941, 'eval_steps_per_second': 0.747, 'epoch': 0.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (18) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0655, 'learning_rate': 4.065517241379311e-06, 'epoch': 0.44}\n",
      "{'loss': 0.065, 'learning_rate': 3.979310344827586e-06, 'epoch': 0.44}\n",
      "{'loss': 0.0536, 'learning_rate': 3.893103448275862e-06, 'epoch': 0.45}\n",
      "{'loss': 0.0652, 'learning_rate': 3.806896551724138e-06, 'epoch': 0.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e24beb24984622929afd400002f4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2350654900074005, 'eval_wer': 18.29624634749382, 'eval_runtime': 148.4421, 'eval_samples_per_second': 6.157, 'eval_steps_per_second': 0.775, 'epoch': 0.46}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (19) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0556, 'learning_rate': 3.720689655172414e-06, 'epoch': 0.46}\n",
      "{'loss': 0.0766, 'learning_rate': 3.63448275862069e-06, 'epoch': 0.47}\n",
      "{'loss': 0.0534, 'learning_rate': 3.5482758620689657e-06, 'epoch': 0.47}\n",
      "{'loss': 0.0515, 'learning_rate': 3.4620689655172418e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84e8bd4bb964b019869b7e3c12c6bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2336333990097046, 'eval_wer': 18.311230988237057, 'eval_runtime': 146.3136, 'eval_samples_per_second': 6.247, 'eval_steps_per_second': 0.786, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (20) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.05, 'learning_rate': 3.3758620689655174e-06, 'epoch': 0.49}\n",
      "{'loss': 0.0461, 'learning_rate': 3.289655172413793e-06, 'epoch': 0.49}\n",
      "{'loss': 0.0609, 'learning_rate': 3.2034482758620695e-06, 'epoch': 0.5}\n",
      "{'loss': 0.0517, 'learning_rate': 3.117241379310345e-06, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4ec220328e4641bd63b36c81cb6698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23231586813926697, 'eval_wer': 18.618416123473438, 'eval_runtime': 152.6157, 'eval_samples_per_second': 5.989, 'eval_steps_per_second': 0.754, 'epoch': 0.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (21) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.059, 'learning_rate': 3.0310344827586207e-06, 'epoch': 0.51}\n",
      "{'loss': 0.061, 'learning_rate': 2.944827586206897e-06, 'epoch': 0.51}\n",
      "{'loss': 0.0544, 'learning_rate': 2.858620689655173e-06, 'epoch': 0.52}\n",
      "{'loss': 0.0547, 'learning_rate': 2.7724137931034484e-06, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b759a28e943c43adb267402f6623ff89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.23019705712795258, 'eval_wer': 19.375140481006966, 'eval_runtime': 151.7491, 'eval_samples_per_second': 6.023, 'eval_steps_per_second': 0.758, 'epoch': 0.53}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (22) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0495, 'learning_rate': 2.6862068965517245e-06, 'epoch': 0.53}\n",
      "{'loss': 0.0546, 'learning_rate': 2.6e-06, 'epoch': 0.54}\n",
      "{'loss': 0.046, 'learning_rate': 2.513793103448276e-06, 'epoch': 0.54}\n",
      "{'loss': 0.0403, 'learning_rate': 2.4275862068965518e-06, 'epoch': 0.55}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f91b6dd80d4c159a883a58ffeb8d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22910059988498688, 'eval_wer': 17.247321495467148, 'eval_runtime': 147.7649, 'eval_samples_per_second': 6.186, 'eval_steps_per_second': 0.778, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (23) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0477, 'learning_rate': 2.341379310344828e-06, 'epoch': 0.56}\n",
      "{'loss': 0.0631, 'learning_rate': 2.2551724137931034e-06, 'epoch': 0.56}\n",
      "{'loss': 0.045, 'learning_rate': 2.1689655172413795e-06, 'epoch': 0.57}\n",
      "{'loss': 0.0608, 'learning_rate': 2.082758620689655e-06, 'epoch': 0.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f85df0b502d04c9da5ed33181d45e9e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22995392978191376, 'eval_wer': 17.78676856222372, 'eval_runtime': 148.5932, 'eval_samples_per_second': 6.151, 'eval_steps_per_second': 0.774, 'epoch': 0.57}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (24) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0553, 'learning_rate': 1.996551724137931e-06, 'epoch': 0.58}\n",
      "{'loss': 0.0469, 'learning_rate': 1.910344827586207e-06, 'epoch': 0.59}\n",
      "{'loss': 0.0547, 'learning_rate': 1.8241379310344828e-06, 'epoch': 0.59}\n",
      "{'loss': 0.0469, 'learning_rate': 1.7379310344827588e-06, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a7e41b9396475fbc07a9f37e0c029d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22850610315799713, 'eval_wer': 17.47209110661572, 'eval_runtime': 148.2037, 'eval_samples_per_second': 6.167, 'eval_steps_per_second': 0.776, 'epoch': 0.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (25) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.045, 'learning_rate': 1.6517241379310347e-06, 'epoch': 0.6}\n",
      "{'loss': 0.0413, 'learning_rate': 1.5655172413793105e-06, 'epoch': 0.61}\n",
      "{'loss': 0.051, 'learning_rate': 1.4793103448275863e-06, 'epoch': 0.62}\n",
      "{'loss': 0.0487, 'learning_rate': 1.3931034482758622e-06, 'epoch': 0.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3181424c123646f7b60166dc5fab3ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22716009616851807, 'eval_wer': 17.502060388102194, 'eval_runtime': 150.7988, 'eval_samples_per_second': 6.061, 'eval_steps_per_second': 0.763, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (26) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0494, 'learning_rate': 1.306896551724138e-06, 'epoch': 0.63}\n",
      "{'loss': 0.0506, 'learning_rate': 1.2206896551724138e-06, 'epoch': 0.63}\n",
      "{'loss': 0.0442, 'learning_rate': 1.1344827586206897e-06, 'epoch': 0.64}\n",
      "{'loss': 0.0421, 'learning_rate': 1.0482758620689657e-06, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194759a811a446119fed41b6081d18db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22669640183448792, 'eval_wer': 16.910167078744287, 'eval_runtime': 148.5877, 'eval_samples_per_second': 6.151, 'eval_steps_per_second': 0.774, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (27) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0445, 'learning_rate': 9.620689655172416e-07, 'epoch': 0.65}\n",
      "{'loss': 0.0431, 'learning_rate': 8.758620689655173e-07, 'epoch': 0.66}\n",
      "{'loss': 0.0421, 'learning_rate': 7.896551724137931e-07, 'epoch': 0.66}\n",
      "{'loss': 0.0433, 'learning_rate': 7.034482758620691e-07, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c45f87de7124d69a326b7ddb3e5d18f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.2270541489124298, 'eval_wer': 16.445643215703903, 'eval_runtime': 148.2598, 'eval_samples_per_second': 6.165, 'eval_steps_per_second': 0.776, 'epoch': 0.67}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (28) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0426, 'learning_rate': 6.172413793103449e-07, 'epoch': 0.68}\n",
      "{'loss': 0.0403, 'learning_rate': 5.310344827586207e-07, 'epoch': 0.68}\n",
      "{'loss': 0.0569, 'learning_rate': 4.448275862068966e-07, 'epoch': 0.69}\n",
      "{'loss': 0.0335, 'learning_rate': 3.5862068965517244e-07, 'epoch': 0.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aa269a6b7b6423fa9155e5465fcb62d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22652219235897064, 'eval_wer': 17.262306136210384, 'eval_runtime': 151.9624, 'eval_samples_per_second': 6.015, 'eval_steps_per_second': 0.757, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (29) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.053, 'learning_rate': 2.7241379310344833e-07, 'epoch': 0.7}\n",
      "{'loss': 0.0482, 'learning_rate': 1.8620689655172414e-07, 'epoch': 0.71}\n",
      "{'loss': 0.0449, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.71}\n",
      "{'loss': 0.0363, 'learning_rate': 1.3793103448275862e-08, 'epoch': 0.72}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c563a247f4447be80068b4f844ba936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/115 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.22629792988300323, 'eval_wer': 17.509552708473812, 'eval_runtime': 150.0777, 'eval_samples_per_second': 6.09, 'eval_steps_per_second': 0.766, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (30) will be pushed upstream.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14090.7439, 'train_samples_per_second': 3.406, 'train_steps_per_second': 0.213, 'train_loss': 0.13040668475627898, 'epoch': 0.72}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3000, training_loss=0.13040668475627898, metrics={'train_runtime': 14090.7439, 'train_samples_per_second': 3.406, 'train_steps_per_second': 0.213, 'train_loss': 0.13040668475627898, 'epoch': 0.72})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "#Load a Pre-Trained Checkpoint\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-ko\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=3000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "#Train\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c5f67f6",
   "metadata": {},
   "source": [
    "Push To hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba709787",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Several commits (32) will be pushed upstream.\n",
      "The progress bars may be unreliable.\n",
      "batch response: Authorization error.\n",
      "error: failed to push some refs to 'https://huggingface.co/trueorfalse441/whisper-small-ko'\n",
      "\n",
      "Error pushing update to the model card. Please read logs and retry.\n",
      "$batch response: Authorization error.\n",
      "error: failed to push some refs to 'https://huggingface.co/trueorfalse441/whisper-small-ko'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"ko-speech\",\n",
    "    \"dataset\": \"Speech Text\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: ko, split: test\",\n",
    "    \"language\": \"ko\",\n",
    "    \"model_name\": \"Whisper Small KR\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}\n",
    "trainer.push_to_hub(kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "6668dc82517539381f024b1d9233ebd900ddcb4832a01457a7e6eb10de2c0a95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
