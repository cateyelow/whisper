{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c684276a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid.\n",
      "Your token has been saved in your configured git credential helpers (manager-core).\n",
      "Your token has been saved to D:\\.cache\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd72e655",
   "metadata": {},
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f1fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Datasets\n",
    "from datasets import load_dataset\n",
    "dataset_test = load_dataset('audiofolder', data_dir='E:/HuggingFace/Test/')\n",
    "print(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b00133734554620af294a2cde0d99e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2439375 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset audiofolder (D:/.cache/datasets/audiofolder/default-d476168ba7a97f78/0.0.0/6cbdd16f8688354c63b4e2a36e1585d05de285023ee6443ffd71c4182055c0fc)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702c8fd29d5f4c9fbdbca97326f9c737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset parquet (D:/.cache/datasets/Bingsu___parquet/Bingsu--zeroth-korean-787ca68963c66467/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f372435a7f43a7afe0aca413452354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fleurs (D:/.cache/datasets/google___fleurs/ko_kr/2.0.0/af82dbec419a815084fa63ebd5d5a9f24a6e9acdf9887b9e3b8c6bbd64e0b7ac)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb76bc5f7dff47a4947384e088913b69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset common_voice_12_0 (D:/.cache/datasets/mozilla-foundation___common_voice_12_0/ko/12.0.0/dd534e3c6006ee4b577c176df4a8ef23bced8b3150a3b64d2d0a7a5e3f942efb)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ff252f79a54789bb226c646d93c5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load Datasets\n",
    "from datasets import load_dataset\n",
    "#dataset_custom = load_dataset('trueorfalse441/Korean_Speech_BigDB')\n",
    "dataset_custom = load_dataset(\"audiofolder\", data_dir=\"E:/HuggingFace/datasets\", cache_dir=\"D:/.cache/datasets/\")\n",
    "dataset_zeroth = load_dataset(\"Bingsu/zeroth-korean\")\n",
    "dataset_fleurs = load_dataset('google/fleurs', 'ko_kr')\n",
    "dataset_common_voice = load_dataset('mozilla-foundation/common_voice_12_0', 'ko')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45b5824",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pushing split train to the Hub.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e952d0afee6405f818255411a011df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e58ee53b59242a1a5e20bea40f53701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/29 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59724de7bac94a21b46ab4d1d80c2270",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9019fba3313a465aaefa4559295fe583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e76531ec8c6149a19b753f91989b754a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3143546c07d48fbbfc29e400b45b61f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e7818202d747dd8567dbb4aab1f51a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "580e598949394373a200cb5bb4ad589f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e9f88ef4a94893bf3f42c2696bdc97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92ca79cf0fdf488ea81dc9e52289fa74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae98073bbe94a11bad328ea0bf197d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84117 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142904e38b4e43be978cd11588947b68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23e0ac1450b490595362657c60bed6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003484c30f104e79a3e0ab7ff0c74869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db898806d7a04547bc72906d045de1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109fc57eefbb4f0cbf69c82d3d3c8601",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61da6b47eb04546944dd4bccb08ff3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0803c437a5f40d798c584b791e0e5f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d3879a97e44892af17adea6153718c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fae976631048c5833a4934152d4741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d79776fb88f3424a81e562a3799b3a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fac709536284d2598377aa6e5adf3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "840743b7972b43aeb497a440aa82833c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b5083a5bd8410f980b1840f4135902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "519e843858054cfeb228c6433030ca3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82449b376ab14d748ce182254d383aec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bfe8644fcf4ed2813d754472cfd147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f880ce1c1be4b4da3596b2da967b70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d0c072d2c84fe0beebc38204d63a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ece2568ad1a4579a950b9bd2786fc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/84116 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e0ebaa1ba44c7389229fb63e9bf333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/85 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488ae07f05fc473b8b0feff0a4bd6629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_custom.push_to_hub(\"trueorfalse441/Korean_Speech_BigDB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a02a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_custom)\n",
    "print(dataset_zeroth)\n",
    "print(dataset_fleurs)\n",
    "print(dataset_common_voice)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c23972b3",
   "metadata": {},
   "source": [
    "PreProcessing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "163800fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fleurs = dataset_fleurs.rename_column('transcription', 'text')\n",
    "dataset_common_voice = dataset_common_voice.rename_column(\"sentence\", 'text')\n",
    "dataset_custom = dataset_custom.rename_column(\"transcription\", 'text')\n",
    "\n",
    "use_cols=['audio', 'text']\n",
    "dataset_fleurs = dataset_fleurs.remove_columns([col for col in dataset_fleurs.column_names['train'] if col not in use_cols])\n",
    "dataset_common_voice = dataset_common_voice.remove_columns([col for col in dataset_common_voice.column_names['train'] if col not in use_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bca5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset_custom)\n",
    "print(dataset_zeroth)\n",
    "print(dataset_fleurs)\n",
    "print(dataset_common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f859919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_custom['train'] =  dataset_custom[\"train\"].shuffle(seed=42).select(range(500000))\n",
    "dataset_custom=dataset_custom['train'].train_test_split(test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ceb971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, IterableDatasetDict\n",
    "from datasets import concatenate_datasets\n",
    "from datasets import interleave_datasets\n",
    "from datasets import Audio\n",
    "\n",
    "dataset_common_voice = dataset_common_voice.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset_fleurs = dataset_fleurs.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset_custom = dataset_custom.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "dataset_zeroth = dataset_zeroth.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "data_dict = DatasetDict()\n",
    "\n",
    "data_dict[\"train\"] = concatenate_datasets(\n",
    "    [\n",
    "        # dataset_fleurs['train'],\n",
    "        # dataset_common_voice['train'],\n",
    "        # dataset_zeroth['train'],\n",
    "        dataset_custom['train'],\n",
    "    ],\n",
    ")\n",
    "\n",
    "data_dict[\"test\"] = concatenate_datasets(\n",
    "    [\n",
    "        # dataset_fleurs['test'],\n",
    "        # dataset_fleurs['validation'],\n",
    "        # dataset_zeroth['test'],\n",
    "        # dataset_common_voice['test'],\n",
    "        # dataset_common_voice['validation'],\n",
    "        dataset_custom['test'],\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f42ef4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 1951499\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 487875\n",
      "    })\n",
      "})\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 1951499\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 487875\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "data_dict = DatasetDict(data_dict)\n",
    "data_dict.column_names\n",
    "print(dataset_custom)\n",
    "print(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "514664a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load FreatureExtractor\n",
    "from transformers import WhisperFeatureExtractor\n",
    "#Load WhisperTokenizer\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930a5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_custom['train'][0]['audio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9399bc3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:                 오늘 점심은 육개장 칼국수에요.\n",
      "Decoded w/ special:    <|startoftranscript|><|ko|><|transcribe|><|notimestamps|>오늘 점심은 육개장 칼국수에요.<|endoftext|>\n",
      "Decoded w/out special: 오늘 점심은 육개장 칼국수에요.\n",
      "Are equal:             True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e3af82018f469db52040ca7af95768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1951499 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\n\u001b[0;32m     31\u001b[0m dataset \u001b[39m=\u001b[39m data_dict\u001b[39m.\u001b[39mcast_column(\u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m, Audio(sampling_rate\u001b[39m=\u001b[39m\u001b[39m16000\u001b[39m))\n\u001b[1;32m---> 33\u001b[0m dataset \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39;49mmap(prepare_dataset, \n\u001b[0;32m     34\u001b[0m                             remove_columns\u001b[39m=\u001b[39;49mdataset\u001b[39m.\u001b[39;49mcolumn_names[\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m], num_proc\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     35\u001b[0m                             writer_batch_size\u001b[39m=\u001b[39;49m\u001b[39m3000\u001b[39;49m,\n\u001b[0;32m     36\u001b[0m                             fn_kwargs\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mfeature_extractor\u001b[39;49m\u001b[39m\"\u001b[39;49m: feature_extractor, \u001b[39m\"\u001b[39;49m\u001b[39mtokenizer\u001b[39;49m\u001b[39m\"\u001b[39;49m: tokenizer},\n\u001b[0;32m     37\u001b[0m                             \u001b[39m#batch_size=100000,\u001b[39;49;00m\n\u001b[0;32m     38\u001b[0m                             \u001b[39m#batched=True,\u001b[39;49;00m\n\u001b[0;32m     39\u001b[0m                             )\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:852\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m--> 852\u001b[0m     {\n\u001b[0;32m    853\u001b[0m         k: dataset\u001b[39m.\u001b[39mmap(\n\u001b[0;32m    854\u001b[0m             function\u001b[39m=\u001b[39mfunction,\n\u001b[0;32m    855\u001b[0m             with_indices\u001b[39m=\u001b[39mwith_indices,\n\u001b[0;32m    856\u001b[0m             with_rank\u001b[39m=\u001b[39mwith_rank,\n\u001b[0;32m    857\u001b[0m             input_columns\u001b[39m=\u001b[39minput_columns,\n\u001b[0;32m    858\u001b[0m             batched\u001b[39m=\u001b[39mbatched,\n\u001b[0;32m    859\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m    860\u001b[0m             drop_last_batch\u001b[39m=\u001b[39mdrop_last_batch,\n\u001b[0;32m    861\u001b[0m             remove_columns\u001b[39m=\u001b[39mremove_columns,\n\u001b[0;32m    862\u001b[0m             keep_in_memory\u001b[39m=\u001b[39mkeep_in_memory,\n\u001b[0;32m    863\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39mload_from_cache_file,\n\u001b[0;32m    864\u001b[0m             cache_file_name\u001b[39m=\u001b[39mcache_file_names[k],\n\u001b[0;32m    865\u001b[0m             writer_batch_size\u001b[39m=\u001b[39mwriter_batch_size,\n\u001b[0;32m    866\u001b[0m             features\u001b[39m=\u001b[39mfeatures,\n\u001b[0;32m    867\u001b[0m             disable_nullable\u001b[39m=\u001b[39mdisable_nullable,\n\u001b[0;32m    868\u001b[0m             fn_kwargs\u001b[39m=\u001b[39mfn_kwargs,\n\u001b[0;32m    869\u001b[0m             num_proc\u001b[39m=\u001b[39mnum_proc,\n\u001b[0;32m    870\u001b[0m             desc\u001b[39m=\u001b[39mdesc,\n\u001b[0;32m    871\u001b[0m         )\n\u001b[0;32m    872\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    873\u001b[0m     }\n\u001b[0;32m    874\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\dataset_dict.py:853\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[39mif\u001b[39;00m cache_file_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     cache_file_names \u001b[39m=\u001b[39m {k: \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m}\n\u001b[0;32m    851\u001b[0m \u001b[39mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m    852\u001b[0m     {\n\u001b[1;32m--> 853\u001b[0m         k: dataset\u001b[39m.\u001b[39;49mmap(\n\u001b[0;32m    854\u001b[0m             function\u001b[39m=\u001b[39;49mfunction,\n\u001b[0;32m    855\u001b[0m             with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[0;32m    856\u001b[0m             with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[0;32m    857\u001b[0m             input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[0;32m    858\u001b[0m             batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[0;32m    859\u001b[0m             batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m    860\u001b[0m             drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[0;32m    861\u001b[0m             remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[0;32m    862\u001b[0m             keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[0;32m    863\u001b[0m             load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[0;32m    864\u001b[0m             cache_file_name\u001b[39m=\u001b[39;49mcache_file_names[k],\n\u001b[0;32m    865\u001b[0m             writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[0;32m    866\u001b[0m             features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[0;32m    867\u001b[0m             disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[0;32m    868\u001b[0m             fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[0;32m    869\u001b[0m             num_proc\u001b[39m=\u001b[39;49mnum_proc,\n\u001b[0;32m    870\u001b[0m             desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[0;32m    871\u001b[0m         )\n\u001b[0;32m    872\u001b[0m         \u001b[39mfor\u001b[39;00m k, dataset \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems()\n\u001b[0;32m    873\u001b[0m     }\n\u001b[0;32m    874\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:563\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    562\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    564\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    565\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[0;32m    566\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:528\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    521\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[0;32m    522\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[0;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[0;32m    524\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[0;32m    525\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[0;32m    526\u001b[0m }\n\u001b[0;32m    527\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[1;32m--> 528\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    529\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[0;32m    530\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:2953\u001b[0m, in \u001b[0;36mDataset.map\u001b[1;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[0;32m   2945\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2946\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[0;32m   2947\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[0;32m   2948\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2951\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   2952\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[1;32m-> 2953\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[0;32m   2954\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[0;32m   2955\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3307\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[1;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[0;32m   3305\u001b[0m _time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m   3306\u001b[0m \u001b[39mfor\u001b[39;00m i, example \u001b[39min\u001b[39;00m shard_iterable:\n\u001b[1;32m-> 3307\u001b[0m     example \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(example, i, offset\u001b[39m=\u001b[39;49moffset)\n\u001b[0;32m   3308\u001b[0m     \u001b[39mif\u001b[39;00m update_data:\n\u001b[0;32m   3309\u001b[0m         \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\datasets\\arrow_dataset.py:3210\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[1;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[0;32m   3208\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[0;32m   3209\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[1;32m-> 3210\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39mfn_args, \u001b[39m*\u001b[39madditional_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfn_kwargs)\n\u001b[0;32m   3211\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[0;32m   3212\u001b[0m     processed_inputs \u001b[39m=\u001b[39m {\n\u001b[0;32m   3213\u001b[0m         k: v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mitems() \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m processed_inputs\u001b[39m.\u001b[39mkeys_to_format\n\u001b[0;32m   3214\u001b[0m     }\n",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m, in \u001b[0;36mprepare_dataset\u001b[1;34m(batch, feature_extractor, tokenizer)\u001b[0m\n\u001b[0;32m      4\u001b[0m audio \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39maudio\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      6\u001b[0m \u001b[39m# compute log-Mel input features from input audio array \u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39minput_features\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m feature_extractor(audio[\u001b[39m\"\u001b[39;49m\u001b[39marray\u001b[39;49m\u001b[39m\"\u001b[39;49m], sampling_rate\u001b[39m=\u001b[39;49maudio[\u001b[39m\"\u001b[39;49m\u001b[39msampling_rate\u001b[39;49m\u001b[39m\"\u001b[39;49m])\u001b[39m.\u001b[39minput_features[\u001b[39m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[39m# encode target text to label ids \u001b[39;00m\n\u001b[0;32m     10\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m tokenizer(batch[\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m])\u001b[39m.\u001b[39minput_ids\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:352\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor.__call__\u001b[1;34m(self, raw_speech, truncation, pad_to_multiple_of, return_tensors, return_attention_mask, padding, max_length, sampling_rate, do_normalize, **kwargs)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39m# make sure list is in array format\u001b[39;00m\n\u001b[0;32m    350\u001b[0m input_features \u001b[39m=\u001b[39m padded_inputs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minput_features\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 352\u001b[0m input_features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_np_extract_fbank_features(waveform) \u001b[39mfor\u001b[39;00m waveform \u001b[39min\u001b[39;00m input_features[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(input_features[\u001b[39m0\u001b[39m], List):\n\u001b[0;32m    355\u001b[0m     padded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_features\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39masarray(feature, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m input_features]\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:352\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[39m# make sure list is in array format\u001b[39;00m\n\u001b[0;32m    350\u001b[0m input_features \u001b[39m=\u001b[39m padded_inputs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39minput_features\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m--> 352\u001b[0m input_features \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_np_extract_fbank_features(waveform) \u001b[39mfor\u001b[39;00m waveform \u001b[39min\u001b[39;00m input_features[\u001b[39m0\u001b[39m]]\n\u001b[0;32m    354\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(input_features[\u001b[39m0\u001b[39m], List):\n\u001b[0;32m    355\u001b[0m     padded_inputs[\u001b[39m\"\u001b[39m\u001b[39minput_features\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39masarray(feature, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat32) \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m input_features]\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:206\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor._np_extract_fbank_features\u001b[1;34m(self, waveform)\u001b[0m\n\u001b[0;32m    203\u001b[0m window \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mhanning(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_fft \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m)[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m    205\u001b[0m frames \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfram_wave(waveform)\n\u001b[1;32m--> 206\u001b[0m stft \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstft(frames, window\u001b[39m=\u001b[39;49mwindow)\n\u001b[0;32m    207\u001b[0m magnitudes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(stft[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m    209\u001b[0m filters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmel_filters\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\whisper\\feature_extraction_whisper.py:195\u001b[0m, in \u001b[0;36mWhisperFeatureExtractor.stft\u001b[1;34m(self, frames, window)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m         fft_signal[:frame_size] \u001b[39m=\u001b[39m frame\n\u001b[1;32m--> 195\u001b[0m     data[f] \u001b[39m=\u001b[39m fft(fft_signal, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)[:num_fft_bins]\n\u001b[0;32m    196\u001b[0m \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39mT\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mfft\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\fft\\_pocketfft.py:215\u001b[0m, in \u001b[0;36mfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    213\u001b[0m     n \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mshape[axis]\n\u001b[0;32m    214\u001b[0m inv_norm \u001b[39m=\u001b[39m _get_forward_norm(n, norm)\n\u001b[1;32m--> 215\u001b[0m output \u001b[39m=\u001b[39m _raw_fft(a, n, axis, \u001b[39mFalse\u001b[39;49;00m, \u001b[39mTrue\u001b[39;49;00m, inv_norm)\n\u001b[0;32m    216\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\skim1\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\fft\\_pocketfft.py:70\u001b[0m, in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, is_real, is_forward, inv_norm)\u001b[0m\n\u001b[0;32m     67\u001b[0m         a \u001b[39m=\u001b[39m z\n\u001b[0;32m     69\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m a\u001b[39m.\u001b[39mndim\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[1;32m---> 70\u001b[0m     r \u001b[39m=\u001b[39m pfi\u001b[39m.\u001b[39;49mexecute(a, is_real, is_forward, fct)\n\u001b[0;32m     71\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     a \u001b[39m=\u001b[39m swapaxes(a, axis, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Prepare Dataset\n",
    "def prepare_dataset(batch, feature_extractor=feature_extractor, tokenizer=tokenizer) :\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "\n",
    "    # compute log-Mel input features from input audio array \n",
    "    batch[\"input_features\"] = feature_extractor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_features[0]\n",
    "\n",
    "    # encode target text to label ids \n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch\n",
    "\n",
    "#Verify Tokenizer\n",
    "input_str = data_dict['train'][0]['text']\n",
    "labels = tokenizer(input_str).input_ids\n",
    "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
    "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
    "\n",
    "print(f\"Input:                 {input_str}\")\n",
    "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
    "print(f\"Decoded w/out special: {decoded_str}\")\n",
    "print(f\"Are equal:             {input_str == decoded_str}\")\n",
    "\n",
    "#Combine To Create A WhisperProcessor\n",
    "from transformers import WhisperProcessor\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"Korean\", task=\"transcribe\")\n",
    "\n",
    "#ReSampling\n",
    "from datasets import Audio\n",
    "import multiprocessing\n",
    "dataset = data_dict.cast_column(\"audio\", Audio(sampling_rate=16000))\n",
    "\n",
    "dataset = dataset.map(prepare_dataset, \n",
    "                            remove_columns=dataset.column_names[\"train\"], num_proc=1,\n",
    "                            writer_batch_size=3000,\n",
    "                            fn_kwargs={\"feature_extractor\": feature_extractor, \"tokenizer\": tokenizer},\n",
    "                            #batch_size=100000,\n",
    "                            #batched=True,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04de1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fce7eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.processor.tokenizer.bos_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch\n",
    "\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor)\n",
    "\n",
    "import evaluate\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}\n",
    "\n",
    "#Load a Pre-Trained Checkpoint\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "model.config.forced_decoder_ids = None\n",
    "model.config.suppress_tokens = []\n",
    "\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./whisper-small-ko-custom-1000h\",  # change to a repo name of your choice\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=100,\n",
    "    max_steps=3000,\n",
    "    gradient_checkpointing=True,\n",
    "    fp16=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_eval_batch_size=8,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    save_steps=100,\n",
    "    eval_steps=100,\n",
    "    logging_steps=25,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "#Train\n",
    "\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2c5f67f6",
   "metadata": {},
   "source": [
    "Push To hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba709787",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {\n",
    "    \"dataset_tags\": \"ko-speech\",\n",
    "    \"dataset\": \"Speech Text\",  # a 'pretty' name for the training dataset\n",
    "    \"dataset_args\": \"config: ko, split: test\",\n",
    "    \"language\": \"ko\",\n",
    "    \"model_name\": \"Whisper Small KR\",  # a 'pretty' name for your model\n",
    "    \"finetuned_from\": \"openai/whisper-small\",\n",
    "    \"tasks\": \"automatic-speech-recognition\",\n",
    "    \"tags\": \"hf-asr-leaderboard\",\n",
    "}\n",
    "trainer.push_to_hub(kwargs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
